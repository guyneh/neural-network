{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for MNIST dataset of digit recognition\n",
    "\n",
    "Tutorial: https://www.geeksforgeeks.org/handwritten-digit-recognition-using-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from tkinter import *\n",
    "from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "normalisation_factor = 1/255        # Each pixel = 8-bit integer (0-255)\n",
    "input_layer_size = 28 * 28          # Number of features (pixels)\n",
    "hidden_layer_size = 100             # Number of hidden units\n",
    "num_labels = 10                     # Number of labels (0-9)\n",
    "maxiter = 100                       # Maximum number of iterations for optimization\n",
    "lambda_reg = 0.1                    # Regularization parameter (prevents overfitting)\n",
    "epsilon = 0.15                      # Random initialisation parameter (prevents symmetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  dict_keys(['__header__', '__version__', '__globals__', 'mldata_descr_ordering', 'data', 'label'])\n",
      "Dataset shape:  (784, 70000)\n"
     ]
    }
   ],
   "source": [
    "# Load mat file of data\n",
    "data = loadmat('../data/mnist-original.mat')\n",
    "print(\"Keys: \", data.keys())\n",
    "print(\"Dataset shape: \", data['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data, X:\n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] \n",
      " (70000, 784)\n",
      "\n",
      "Labels, y:\n",
      "  [0. 0. 0. ... 9. 9. 9.] \n",
      " (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Extract features and transpose\n",
    "X = data['data'].T\n",
    "\n",
    "# Normalise the data so that each pixel is in the range [0, 1]\n",
    "X = X * normalisation_factor\n",
    "\n",
    "# Extract labels from data and flatten\n",
    "y = data['label'].flatten()\n",
    "\n",
    "print(\"Data, X:\\n \", X, \"\\n\", X.shape)\n",
    "print(\"\\nLabels, y:\\n \", y, \"\\n\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  (60000, 784) (60000,)\n",
      "Testing size:  (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training set with 60,000 samples and test set with 10,000 samples (capital for matrix, lower case for vector)\n",
    "X_train = X[:60000, :]\n",
    "y_train = y[:60000]\n",
    "print(\"Training size: \", X_train.shape, y_train.shape)\n",
    "\n",
    "# (2nd colon specifies all columns)\n",
    "X_test = X[60000:, :]\n",
    "y_test = y[60000:]\n",
    "print(\"Testing size: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample image (random by default)\n",
    "def show_image(X, y, index=None):\n",
    "    # Choose a random index if none is provided\n",
    "    if index is None:\n",
    "        N = X.shape[0]\n",
    "        index = np.random.randint(0, N - 1)\n",
    "    \n",
    "    # Extract image data and label\n",
    "    image = X[index].reshape(28, 28)\n",
    "    label = y[index]\n",
    "    \n",
    "    # Display image and label\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# Choose a random index from the total number of images\n",
    "show_image(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta1:\n",
      "  [[-0.10523992  0.13631222  0.11490947 ... -0.04409382  0.14596393\n",
      "  -0.04316191]\n",
      " [-0.00843688 -0.03487382  0.1132519  ... -0.03262799 -0.10660964\n",
      "   0.05749073]\n",
      " [ 0.01376691  0.00648702  0.14856307 ... -0.05335507 -0.07088186\n",
      "  -0.12227181]\n",
      " ...\n",
      " [-0.10948283 -0.12147237  0.12925815 ... -0.12255489  0.02639999\n",
      "   0.03705386]\n",
      " [-0.13178417 -0.02957788  0.11081667 ...  0.02010976 -0.10072104\n",
      "  -0.03033869]\n",
      " [ 0.02258552 -0.08295611  0.10596016 ... -0.07043072 -0.08747693\n",
      "   0.00749159]] \n",
      " (100, 785)\n",
      "\n",
      "Theta2:\n",
      "  [[ 0.07322441 -0.14034795  0.10544055 ...  0.06743076  0.07155757\n",
      "  -0.12102869]\n",
      " [-0.03452996 -0.14972879 -0.05731393 ...  0.09926521 -0.01213258\n",
      "   0.00655153]\n",
      " [ 0.09498755  0.03702895 -0.12360815 ...  0.10178058 -0.04782588\n",
      "   0.00432265]\n",
      " ...\n",
      " [-0.05111819  0.02448872  0.12999038 ...  0.09047151 -0.07048585\n",
      "   0.0058379 ]\n",
      " [ 0.03599399  0.11809842  0.0211456  ...  0.07063103 -0.01359112\n",
      "   0.01685608]\n",
      " [-0.11344077  0.06483458  0.08278755 ... -0.08280649 -0.13874373\n",
      "   0.09190499]] \n",
      " (10, 101)\n"
     ]
    }
   ],
   "source": [
    "# Function to randomly initialise Thetas (weights) between a range of [-epsilon, epsilon]\n",
    "def initialise(a, b, epsilon):\n",
    "    # Scale and shift random values to be within range\n",
    "    c = (np.random.rand(a, b + 1) * (2 * epsilon)) - epsilon\n",
    "    \n",
    "    # Returns matrix of randomly initialised weights, of dimensions a x (b + 1)\n",
    "    return c\n",
    "\n",
    "# Chosen arbitrarily (small enough to avoid saturation and large enough to avoid vanishing gradients)\n",
    "initial_Theta1 = initialise(hidden_layer_size, input_layer_size, epsilon)\n",
    "initial_Theta2 = initialise(num_labels, hidden_layer_size, epsilon)\n",
    "print(\"Theta1:\\n \", initial_Theta1, \"\\n\", initial_Theta1.shape)\n",
    "print(\"\\nTheta2:\\n \", initial_Theta2, \"\\n\", initial_Theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters:  (79510,)\n"
     ]
    }
   ],
   "source": [
    "# Unroll (combine) the weight matrices into a single column vector (easier for optimisation algorithm)\n",
    "initial_nn_params = np.concatenate((initial_Theta1.flatten(), initial_Theta2.flatten()))\n",
    "print(\"Initial parameters: \", initial_nn_params.shape)\n",
    "\n",
    "# Package all arguments into a tuple for optimisation function\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, y_train, lambda_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why 79,510?\n",
    "`Theta1`\n",
    "-   hidden_layer_size * (input_layer_size + 1)\n",
    "-   100 * (784 + 1)\n",
    "-   78,500\n",
    "\n",
    "`Theta2`\n",
    "-   num_labels * (hidden_layer_size + 1)\n",
    "-   10 * (100 + 1)\n",
    "-   1,010\n",
    "\n",
    "`TOTAL`\n",
    "-   79,510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform forward propagation on the data maxtrix and weight matrices\n",
    "def forward_propagation(X, Theta1, Theta2):\n",
    "    m = X.shape[0]\n",
    "    ones = np.ones((m, 1))              # Ones matrix for bias unit\n",
    "    X = np.append(ones, X, axis=1)      # Add bias unit to input layer\n",
    "    a1 = X                              # Input layer\n",
    "    z2 = np.dot(a1, Theta1.T)           # Compute z2 for hidden layer\n",
    "    a2 = 1 / (1 + np.exp(-z2))          # Activation for hidden layer\n",
    "    a2 = np.append(ones, a2, axis=1)    # Add bias unit to hidden layer\n",
    "    z3 = np.dot(a2, Theta2.T)           # Compute z3 for output layer\n",
    "    a3 = 1 / (1 + np.exp(-z3))          # Activation for output layer (final hypothesis)\n",
    "    \n",
    "    return a1, z2, a2, z3, a3\n",
    "\n",
    "# Calculate the cost function\n",
    "def cost_function(a3, y, Theta1, Theta2, lamb):\n",
    "    m = y.shape[0]\n",
    "    num_labels = a3.shape[1]\n",
    "    \n",
    "    # Convert y labels into binary vectors\n",
    "    y_vect = np.zeros((m, num_labels))\n",
    "    for i in range(m):\n",
    "        y_vect[i, int(y[i])] = 1\n",
    "    \n",
    "    # Calculate the cost\n",
    "    J = (\n",
    "        (1 / m) * \n",
    "        (np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))\n",
    "        + \n",
    "        (lamb / (2 * m)) * \n",
    "        (np.sum(np.sum(Theta1[:, 1:] ** 2)) + np.sum(np.sum(Theta2[:, 1:] ** 2)))\n",
    "    )\n",
    "    \n",
    "    return J\n",
    "\n",
    "# Perform back propagation on the data matrix and weight matrices\n",
    "def back_propagation(a1, z2, a2, a3, y, Theta1, Theta2):\n",
    "    m = y.shape[0]\n",
    "    num_labels = a3.shape[1]\n",
    "    \n",
    "    # Convert y labels into binary vectors\n",
    "    y_vect = np.zeros((m, num_labels))\n",
    "    for i in range(m):\n",
    "        y_vect[i, int(y[i])] = 1\n",
    "    \n",
    "    # Compute deltas\n",
    "    Delta3 = a3 - y_vect\n",
    "    Delta2 = np.dot(Delta3, Theta2) * a2 * (1 - a2)\n",
    "    Delta2 = Delta2[:, 1:]  # Remove bias term from Delta2\n",
    "    \n",
    "    return Delta3, Delta2\n",
    "\n",
    "# Compute the gradients of the cost function\n",
    "def compute_gradients(Delta2, Delta3, a1, a2, Theta1, Theta2, lamb):\n",
    "    m = a1.shape[0]\n",
    "    \n",
    "    # Set the first column of Theta1 and Theta2 to zero (bias terms are not regularized)\n",
    "    Theta1[:, 0] = 0\n",
    "    Theta2[:, 0] = 0\n",
    "    \n",
    "    # Compute the gradients\n",
    "    Theta1_grad = (1 / m) * np.dot(Delta2.T, a1) + (lamb / m) * Theta1\n",
    "    Theta2_grad = (1 / m) * np.dot(Delta3.T, a2) + (lamb / m) * Theta2\n",
    "    \n",
    "    # Flatten gradients to return a single vector\n",
    "    grad = np.concatenate((Theta1_grad.flatten(), Theta2_grad.flatten()))\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "# Create the neural network model\n",
    "def neural_network(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lamb):\n",
    "    # Unroll the parameters\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (hidden_layer_size, input_layer_size + 1))\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], (num_labels, hidden_layer_size + 1))\n",
    "    \n",
    "    # Forward propagation\n",
    "    a1, z2, a2, z3, a3 = forward_propagation(X, Theta1, Theta2)\n",
    "    \n",
    "    # Cost function\n",
    "    J = cost_function(a3, y, Theta1, Theta2, lamb)\n",
    "    \n",
    "    # Back propagation\n",
    "    Delta3, Delta2 = back_propagation(a1, z2, a2, a3, y, Theta1, Theta2)\n",
    "    \n",
    "    # Compute gradients\n",
    "    grad = compute_gradients(Delta2, Delta3, a1, a2, Theta1, Theta2, lamb)\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.optimize.minimize`\n",
    "Generic optimisation function to find the minimum of a scalar function\n",
    "-   Objective Function: cost function of NN\n",
    "-   Initial Guess: initial estimate of params (weights) to optimise\n",
    "-   Method: optimisation algorithm to be used\n",
    "-   Jac: Jacobian (gradient) of objective function\n",
    "-   Options: e.g. number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        79510     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.12404D+00    |proj g|=  5.88704D-01\n",
      "\n",
      "At iterate    1    f=  3.68942D+00    |proj g|=  1.28763D-01\n",
      "\n",
      "At iterate    2    f=  3.30603D+00    |proj g|=  4.05214D-02\n",
      "\n",
      "At iterate    3    f=  3.22686D+00    |proj g|=  2.05710D-02\n",
      "\n",
      "At iterate    4    f=  3.18929D+00    |proj g|=  2.36864D-02\n",
      "\n",
      "At iterate    5    f=  3.08329D+00    |proj g|=  3.25391D-02\n",
      "\n",
      "At iterate    6    f=  2.82260D+00    |proj g|=  5.68133D-02\n",
      "\n",
      "At iterate    7    f=  2.19226D+00    |proj g|=  7.25880D-02\n",
      "\n",
      "At iterate    8    f=  1.79221D+00    |proj g|=  1.02031D-01\n",
      "\n",
      "At iterate    9    f=  1.42774D+00    |proj g|=  3.18956D-02\n",
      "\n",
      "At iterate   10    f=  1.36638D+00    |proj g|=  1.85342D-02\n",
      "\n",
      "At iterate   11    f=  1.30546D+00    |proj g|=  1.90710D-02\n",
      "\n",
      "At iterate   12    f=  1.18257D+00    |proj g|=  2.30515D-02\n",
      "\n",
      "At iterate   13    f=  1.04140D+00    |proj g|=  2.60660D-02\n",
      "\n",
      "At iterate   14    f=  9.80013D-01    |proj g|=  2.92355D-02\n",
      "\n",
      "At iterate   15    f=  9.08875D-01    |proj g|=  1.18713D-02\n",
      "\n",
      "At iterate   16    f=  8.51252D-01    |proj g|=  9.52011D-03\n",
      "\n",
      "At iterate   17    f=  7.86983D-01    |proj g|=  1.87673D-02\n",
      "\n",
      "At iterate   18    f=  7.34951D-01    |proj g|=  1.24094D-02\n",
      "\n",
      "At iterate   19    f=  7.01007D-01    |proj g|=  7.19116D-03\n",
      "\n",
      "At iterate   20    f=  6.62116D-01    |proj g|=  8.54382D-03\n",
      "\n",
      "At iterate   21    f=  6.37231D-01    |proj g|=  1.62714D-02\n",
      "\n",
      "At iterate   22    f=  6.12253D-01    |proj g|=  5.99154D-03\n",
      "\n",
      "At iterate   23    f=  5.83614D-01    |proj g|=  7.69166D-03\n",
      "\n",
      "At iterate   24    f=  5.57783D-01    |proj g|=  6.74098D-03\n",
      "\n",
      "At iterate   25    f=  5.32558D-01    |proj g|=  1.09058D-02\n",
      "\n",
      "At iterate   26    f=  5.10533D-01    |proj g|=  4.08445D-03\n",
      "\n",
      "At iterate   27    f=  4.96966D-01    |proj g|=  3.44265D-03\n",
      "\n",
      "At iterate   28    f=  4.74504D-01    |proj g|=  4.72897D-03\n",
      "\n",
      "At iterate   29    f=  4.62616D-01    |proj g|=  5.89773D-03\n",
      "\n",
      "At iterate   30    f=  4.50905D-01    |proj g|=  4.95764D-03\n",
      "\n",
      "At iterate   31    f=  4.26937D-01    |proj g|=  6.25799D-03\n",
      "\n",
      "At iterate   32    f=  4.13312D-01    |proj g|=  8.84635D-03\n",
      "\n",
      "At iterate   33    f=  4.02712D-01    |proj g|=  3.93006D-03\n",
      "\n",
      "At iterate   34    f=  3.86281D-01    |proj g|=  2.77937D-03\n",
      "\n",
      "At iterate   35    f=  3.72580D-01    |proj g|=  4.75182D-03\n",
      "\n",
      "At iterate   36    f=  3.58047D-01    |proj g|=  6.01422D-03\n",
      "\n",
      "At iterate   37    f=  3.45593D-01    |proj g|=  3.59907D-03\n",
      "\n",
      "At iterate   38    f=  3.33898D-01    |proj g|=  2.81384D-03\n",
      "\n",
      "At iterate   39    f=  3.25540D-01    |proj g|=  6.51229D-03\n",
      "\n",
      "At iterate   40    f=  3.16752D-01    |proj g|=  3.28078D-03\n",
      "\n",
      "At iterate   41    f=  3.06338D-01    |proj g|=  3.05035D-03\n",
      "\n",
      "At iterate   42    f=  2.97655D-01    |proj g|=  3.44448D-03\n",
      "\n",
      "At iterate   43    f=  2.88939D-01    |proj g|=  2.96064D-03\n",
      "\n",
      "At iterate   44    f=  2.82632D-01    |proj g|=  5.09741D-03\n",
      "\n",
      "At iterate   45    f=  2.75185D-01    |proj g|=  2.73139D-03\n",
      "\n",
      "At iterate   46    f=  2.68598D-01    |proj g|=  1.87552D-03\n",
      "\n",
      "At iterate   47    f=  2.63013D-01    |proj g|=  2.10546D-03\n",
      "\n",
      "At iterate   48    f=  2.51834D-01    |proj g|=  4.10817D-03\n",
      "\n",
      "At iterate   49    f=  2.42822D-01    |proj g|=  2.57623D-03\n",
      "\n",
      "At iterate   50    f=  2.36143D-01    |proj g|=  1.21477D-03\n",
      "\n",
      "At iterate   51    f=  2.29856D-01    |proj g|=  1.63079D-03\n",
      "\n",
      "At iterate   52    f=  2.23886D-01    |proj g|=  4.30125D-03\n",
      "\n",
      "At iterate   53    f=  2.17205D-01    |proj g|=  2.66988D-03\n",
      "\n",
      "At iterate   54    f=  2.11510D-01    |proj g|=  1.52175D-03\n",
      "\n",
      "At iterate   55    f=  2.06031D-01    |proj g|=  2.38356D-03\n",
      "\n",
      "At iterate   56    f=  2.00784D-01    |proj g|=  1.90051D-03\n",
      "\n",
      "At iterate   57    f=  1.94595D-01    |proj g|=  3.16576D-03\n",
      "\n",
      "At iterate   58    f=  1.89220D-01    |proj g|=  2.98595D-03\n",
      "\n",
      "At iterate   59    f=  1.85449D-01    |proj g|=  1.19086D-03\n",
      "\n",
      "At iterate   60    f=  1.81173D-01    |proj g|=  1.03995D-03\n",
      "\n",
      "At iterate   61    f=  1.75639D-01    |proj g|=  3.21316D-03\n",
      "\n",
      "At iterate   62    f=  1.69530D-01    |proj g|=  1.87676D-03\n",
      "\n",
      "At iterate   63    f=  1.65670D-01    |proj g|=  9.00704D-04\n",
      "\n",
      "At iterate   64    f=  1.61253D-01    |proj g|=  1.48696D-03\n",
      "\n",
      "At iterate   65    f=  1.57680D-01    |proj g|=  1.70125D-03\n",
      "\n",
      "At iterate   66    f=  1.53913D-01    |proj g|=  1.29993D-03\n",
      "\n",
      "At iterate   67    f=  1.50106D-01    |proj g|=  8.12320D-04\n",
      "\n",
      "At iterate   68    f=  1.46828D-01    |proj g|=  1.76304D-03\n",
      "\n",
      "At iterate   69    f=  1.43348D-01    |proj g|=  1.10437D-03\n",
      "\n",
      "At iterate   70    f=  1.40287D-01    |proj g|=  8.63816D-04\n",
      "\n",
      "At iterate   71    f=  1.36467D-01    |proj g|=  1.46019D-03\n",
      "\n",
      "At iterate   72    f=  1.33304D-01    |proj g|=  1.92770D-03\n",
      "\n",
      "At iterate   73    f=  1.30533D-01    |proj g|=  1.23542D-03\n",
      "\n",
      "At iterate   74    f=  1.26683D-01    |proj g|=  7.83731D-04\n",
      "\n",
      "At iterate   75    f=  1.24019D-01    |proj g|=  1.26666D-03\n",
      "\n",
      "At iterate   76    f=  1.20499D-01    |proj g|=  2.22873D-03\n",
      "\n",
      "At iterate   77    f=  1.16928D-01    |proj g|=  1.03074D-03\n",
      "\n",
      "At iterate   78    f=  1.15197D-01    |proj g|=  7.87631D-04\n",
      "\n",
      "At iterate   79    f=  1.11608D-01    |proj g|=  1.45320D-03\n",
      "\n",
      "At iterate   80    f=  1.09719D-01    |proj g|=  2.84431D-03\n",
      "\n",
      "At iterate   81    f=  1.06955D-01    |proj g|=  1.18466D-03\n",
      "\n",
      "At iterate   82    f=  1.05031D-01    |proj g|=  6.36980D-04\n",
      "\n",
      "At iterate   83    f=  1.02904D-01    |proj g|=  1.11631D-03\n",
      "\n",
      "At iterate   84    f=  1.00531D-01    |proj g|=  2.40415D-03\n",
      "\n",
      "At iterate   85    f=  9.75364D-02    |proj g|=  9.08285D-04\n",
      "\n",
      "At iterate   86    f=  9.56489D-02    |proj g|=  4.09711D-04\n",
      "\n",
      "At iterate   87    f=  9.37393D-02    |proj g|=  8.90409D-04\n",
      "\n",
      "At iterate   88    f=  9.10278D-02    |proj g|=  1.81798D-03\n",
      "\n",
      "At iterate   89    f=  8.86855D-02    |proj g|=  1.79218D-03\n",
      "\n",
      "At iterate   90    f=  8.66503D-02    |proj g|=  5.62153D-04\n",
      "\n",
      "At iterate   91    f=  8.45915D-02    |proj g|=  9.69289D-04\n",
      "\n",
      "At iterate   92    f=  8.28977D-02    |proj g|=  1.06552D-03\n",
      "\n",
      "At iterate   93    f=  8.09282D-02    |proj g|=  2.24355D-03\n",
      "\n",
      "At iterate   94    f=  7.79660D-02    |proj g|=  7.76303D-04\n",
      "\n",
      "At iterate   95    f=  7.65517D-02    |proj g|=  6.09695D-04\n",
      "\n",
      "At iterate   96    f=  7.45751D-02    |proj g|=  1.09967D-03\n",
      "\n",
      "At iterate   97    f=  7.27834D-02    |proj g|=  1.51740D-03\n",
      "\n",
      "At iterate   98    f=  7.07810D-02    |proj g|=  9.42731D-04\n",
      "\n",
      "At iterate   99    f=  6.88354D-02    |proj g|=  2.85238D-04\n",
      "\n",
      "  message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "  success: False\n",
      "   status: 1\n",
      "      fun: 0.06733709188391802\n",
      "        x: [-5.861e-01  1.322e-01 ...  5.637e-01  2.295e-02]\n",
      "      nit: 100\n",
      "      jac: [-8.652e-05  2.203e-07 ... -1.689e-04 -1.369e-04]\n",
      "     nfev: 104\n",
      "     njev: 104\n",
      " hess_inv: <79510x79510 LbfgsInvHessProduct with dtype=float64>\n",
      "At iterate  100    f=  6.73371D-02    |proj g|=  7.53767D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "79510    100    104      1     0     0   7.538D-04   6.734D-02\n",
      "  F =   6.7337091883918024E-002\n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    }
   ],
   "source": [
    "# Minimise the cost function using the L-BFGS-B optimisation algorithm\n",
    "results = minimize(neural_network, x0=initial_nn_params, args=myargs, options={'disp': True, 'maxiter': maxiter}, method='L-BFGS-B', jac=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Objective / Cost function`\n",
    "| Variable | Definition                                                                     |\n",
    "| -------- | -------                                                                        |\n",
    "| N        | total number of variables (parameters, weights)                                |\n",
    "| M        | number of corrections (updates) stored in memory by the algorithm              |\n",
    "| X0       | none of the variables are at their bounds                                      |\n",
    "| f        | current value of cost function                                                 |\n",
    "| proj g   | norm of projected gradient (how close optimisation is to a stationary point)   |\n",
    "| success  | whether optimisation converged or not (did not)                                |\n",
    "| fun      | value of cost function @ final params                                          |\n",
    "| x        | final values of params (weights)                                               |\n",
    "| nit      | number of iterations performed                                                 |\n",
    "| jac      | gradient of cost function @ final params                                       |\n",
    "| nfev     | # times cost function was evaluated                                            |\n",
    "| njev     | # times gradient was evaluated                                                 |\n",
    "| hess_inv | inverse of the approx Hessian matrix @ final point (helps understand curvature)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised weights: \n",
      " [-0.58609539  0.13218445  0.11142981 ... -2.93568529  0.56368882\n",
      "  0.02294904] \n",
      " (79510,)\n"
     ]
    }
   ],
   "source": [
    "# Extract the optimised weights (trained Theta)\n",
    "nn_params = results[\"x\"]\n",
    "print(\"Optimised weights: \\n\", nn_params, \"\\n\", nn_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 785) (10, 101)\n"
     ]
    }
   ],
   "source": [
    "# Split weights back into Theta1 (100 x 785) and Theta2 (10 x 101)\n",
    "Theta1 = np.reshape(nn_params[:(hidden_layer_size * (input_layer_size + 1))], (hidden_layer_size, (input_layer_size + 1)))\n",
    "Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):], (num_labels, (hidden_layer_size + 1)))\n",
    "print(Theta1.shape, Theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  97.28\n",
      "Train set accuracy:  99.50333333333333\n"
     ]
    }
   ],
   "source": [
    "# Performs forward propagation to predict the label (digit) of an input image\n",
    "def predict(Theta1, Theta2, X):\n",
    "    m = X.shape[0] \n",
    "    ones = np.ones((m, 1))                      # Ones matrix\n",
    "    X = np.append(ones, X, axis=1)              # Add bias unit to input (first) layer \n",
    "    z2 = np.dot(X, Theta1.transpose()) \n",
    "    a2 = 1 / (1 + np.exp(-z2))                  # Activation for hidden (second) layer\n",
    "    ones = np.ones((m, 1)) \n",
    "    a2 = np.append(ones, a2, axis=1)            # Adding bias unit to hidden layer \n",
    "    z3 = np.dot(a2, Theta2.transpose()) \n",
    "    a3 = 1 / (1 + np.exp(-z3))                  # Activation for output (third) layer \n",
    "    p = (np.argmax(a3, axis=1))                 # Predicting the class on the basis of max value of hypothesis \n",
    "    return p \n",
    "\n",
    "\n",
    "# Check test set accuracy of model\n",
    "pred = predict(Theta1, Theta2, X_test)\n",
    "print(\"Test set accuracy: \", np.mean(pred == y_test) * 100)\n",
    "\n",
    "# Check train set accuracy of model\n",
    "pred = predict(Theta1, Theta2, X_train)\n",
    "print(\"Train set accuracy: \", np.mean(pred == y_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9950333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate precision of model \n",
    "true_positive = 0\n",
    "\n",
    "# Iterate through predictions and compare with actual labels\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == y_train[i]:\n",
    "        true_positive += 1\n",
    "        \n",
    "# Calculate precision\n",
    "false_positive = len(y_train) - true_positive \n",
    "print('Precision =', true_positive/(true_positive + false_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Thetas in .txt files: (100 x 785) and (10 x 101)\n",
    "np.savetxt('Theta1.txt', Theta1, delimiter=' ') \n",
    "np.savetxt('Theta2.txt', Theta2, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop up widget to draw digit and output model prediction\n",
    "window = Tk() \n",
    "window.title(\"Handwritten digit recognition\") \n",
    "l1 = Label() \n",
    "\n",
    "\n",
    "def MyProject():\n",
    "\tglobal l1 \n",
    "\n",
    "\twidget = cv \n",
    "\t# Setting co-ordinates of canvas\n",
    "\tx = window.winfo_rootx() + widget.winfo_x() \n",
    "\ty = window.winfo_rooty() + widget.winfo_y() \n",
    "\tx1 = x + widget.winfo_width() \n",
    "\ty1 = y + widget.winfo_height() \n",
    "\n",
    "\t# Image is captured from canvas and is resized to (28 X 28) px \n",
    "\timg = ImageGrab.grab().crop((x, y, x1, y1)).resize((28, 28)) \n",
    "\n",
    "\t# Converting rgb to grayscale image \n",
    "\timg = img.convert('L') \n",
    "\n",
    "\t# Extracting pixel matrix of image and converting it to a vector of (1, 784) \n",
    "\tx = np.asarray(img) \n",
    "\tvec = np.zeros((1, 784)) \n",
    "\tk = 0\n",
    "\tfor i in range(28): \n",
    "\t\tfor j in range(28): \n",
    "\t\t\tvec[0][k] = x[i][j] \n",
    "\t\t\tk += 1\n",
    "\n",
    "\t# Loading Thetas \n",
    "\tTheta1 = np.loadtxt('Theta1.txt') \n",
    "\tTheta2 = np.loadtxt('Theta2.txt')\n",
    "\n",
    "\t# Calling function for prediction \n",
    "\tpred = predict(Theta1, Theta2, vec / 255)\n",
    "\n",
    "\t# Displaying the result \n",
    "\tl1 = Label(window, text=\"Digit = \" + str(pred[0]), font=('Algerian', 20)) \n",
    "\tl1.place(x=230, y=420) \n",
    "\n",
    "\n",
    "lastx, lasty = None, None\n",
    "\n",
    "\n",
    "# Clears the canvas \n",
    "def clear_widget(): \n",
    "\tglobal cv, l1 \n",
    "\tcv.delete(\"all\") \n",
    "\tl1.destroy() \n",
    "\n",
    "\n",
    "# Activate canvas\n",
    "def event_activation(event): \n",
    "\tglobal lastx, lasty \n",
    "\tcv.bind('<B1-Motion>', draw_lines) \n",
    "\tlastx, lasty = event.x, event.y \n",
    "\n",
    "\n",
    "# To draw on canvas \n",
    "def draw_lines(event): \n",
    "\tglobal lastx, lasty \n",
    "\tx, y = event.x, event.y \n",
    "\tcv.create_line((lastx, lasty, x, y), width=30, fill='white', capstyle=ROUND, smooth=TRUE, splinesteps=12) \n",
    "\tlastx, lasty = x, y \n",
    "\n",
    "\n",
    "# Label \n",
    "L1 = Label(window, text=\"Handwritten Digit Recoginition\", font=('Algerian', 25), fg=\"blue\") \n",
    "L1.place(x=35, y=10) \n",
    "\n",
    "# Button to clear canvas \n",
    "b1 = Button(window, text=\"1. Clear Canvas\", font=('Algerian', 15), bg=\"orange\", fg=\"black\", command=clear_widget) \n",
    "b1.place(x=120, y=370) \n",
    "\n",
    "# Button to predict digit drawn on canvas \n",
    "b2 = Button(window, text=\"2. Prediction\", font=('Algerian', 15), bg=\"white\", fg=\"red\", command=MyProject) \n",
    "b2.place(x=320, y=370) \n",
    "\n",
    "# Setting properties of canvas \n",
    "cv = Canvas(window, width=350, height=290, bg='black') \n",
    "cv.place(x=120, y=70) \n",
    "\n",
    "cv.bind('<Button-1>', event_activation) \n",
    "window.geometry(\"600x500\") \n",
    "window.mainloop() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
